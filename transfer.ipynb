{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31bbe01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from sa_convlstm import SAConvLSTM\n",
    "from convlstm import ConvLSTM\n",
    "from utils import *\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import sys\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import math\n",
    "import argparse\n",
    "import json\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef627745",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dir = './save_models/saclstm_orth_2_epoch_50_pinchu_pandamonium/'\n",
    "save_dir = load_dir[:-1] + \"_transfer/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8cc5d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "transfer_epochs = 1\n",
    "transfer_data = \"./WeatherBenchData/wthrbnch_air_pv_PUV_sh_u_v_5.625deg_24.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29881bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "args = parser.parse_args(args=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad835e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(load_dir + 'args.txt', 'r') as f:\n",
    "    args.__dict__ = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a633b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.num_epochs = transfer_epochs\n",
    "args.data = transfer_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876ee7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 1234\n",
    "np.random.seed(random_seed)\n",
    "torch.manual_seed(random_seed)\n",
    "\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "    \n",
    "with open(save_dir+'args.txt', 'w') as f:\n",
    "    json.dump(args.__dict__, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93af3fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainFolder = wb_dataset(root=args.data, dataset_type=\"train\", frames_input=args.input_length,\n",
    "                              frames_output=args.output_length, prob = args.prob_crps)\n",
    "\n",
    "validFolder = wb_dataset(root=args.data, dataset_type=\"eval\", frames_input=args.input_length,\n",
    "                              frames_output=args.output_length, prob = args.prob_crps)\n",
    "\n",
    "trainLoader = torch.utils.data.DataLoader(trainFolder,\n",
    "                                          batch_size=args.batch_size,\n",
    "                                          shuffle=True)\n",
    "\n",
    "validLoader = torch.utils.data.DataLoader(validFolder,\n",
    "                                          batch_size=args.batch_size,\n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a9aa23",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.convlstm and not args.prob_crps:\n",
    "    network = ConvLSTM(args.input_dim, args.hidden_dim, args.output_dim,\n",
    "                             args.kernel_size, device, dropout=args.dropout).to(device)\n",
    "elif args.convlstm and args.prob_crps:\n",
    "    network = ConvLSTM(2*args.input_dim, args.hidden_dim, 2*args.output_dim,\n",
    "                       args.kernel_size, device, dropout=args.dropout).to(device)\n",
    "elif args.saconvlstm and not args.prob_crps:\n",
    "    network = SAConvLSTM(args.input_dim, args.hidden_dim, args.output_dim, args.attn_dim,\n",
    "                         args.kernel_size, device, dropout=args.dropout).to(device)\n",
    "else:\n",
    "    network = SAConvLSTM(2*args.input_dim, args.hidden_dim, 2*args.output_dim, args.attn_dim,\n",
    "                         args.kernel_size, device, dropout=args.dropout).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd341212",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(network.parameters(), lr=args.learn_rate, weight_decay=args.weight_decay)    \n",
    "lr_scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.3, patience=0, verbose=True, min_lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2aea47",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_ep = 0\n",
    "for f in os.listdir(load_dir):\n",
    "    split = f.split(\"_\")\n",
    "    if len(split)==2 and split[1] == \"checkpoint.chk\":\n",
    "        if max_ep<int(split[0]): max_ep=int(split[0])\n",
    "chkpnt = str(max_ep) + \"_checkpoint.chk\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69a8093",
   "metadata": {},
   "outputs": [],
   "source": [
    "chk = torch.load(load_dir + chkpnt)\n",
    "network.load_state_dict(chk['net'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78982a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in network.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in network.layers[3].parameters():\n",
    "    param.requires_grad = True\n",
    "for param in network.conv_output.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d05d446",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transfer_train():\n",
    "    cur_epoch = 0\n",
    "    epoch_eval_loss = []\n",
    "    epoch_eval_wb_loss = []\n",
    "    count = 0\n",
    "    best = math.inf\n",
    "    ssr_ratio = 1\n",
    "    for i in range(cur_epoch, args.num_epochs):\n",
    "        print('\\nepoch: {0}'.format(i))\n",
    "        network.train()\n",
    "        t = tqdm(trainLoader, leave=False, total=len(trainLoader))\n",
    "        for j, mc in enumerate(t):\n",
    "            if ssr_ratio > 0:\n",
    "                ssr_ratio = max(ssr_ratio - args.ssr_decay_rate, 0)\n",
    "                \n",
    "            mc_pred = network(mc.float(), teacher_forcing=True, scheduled_sampling_ratio=ssr_ratio, train=True)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            if args.prob_crps:\n",
    "                loss = loss_prob(mc_pred, mc[:, 1:].to(device), args.output_dim) \n",
    "            else:\n",
    "                loss = loss_mc(mc_pred, mc[:, 1:].to(device))\n",
    "            \n",
    "            loss.backward()                                                                                             \n",
    "            if args.gradient_clipping:\n",
    "                nn.utils.clip_grad_norm_(network.parameters(), args.clipping_threshold)\n",
    "            optimizer.step()\n",
    "\n",
    "            if j % 2500 == 0:\n",
    "                print('batch training loss: {:.5f}, ssr ratio: {:.4f}'.format(loss, ssr_ratio))\n",
    "\n",
    "        # evaluation\n",
    "        loss_mc_eval = infer(validLoader, args.input_length, network, args.output_dim, args.prob_crps)\n",
    "        epoch_eval_loss.append(loss_mc_eval)\n",
    "        loss_wb_eval = infer_WB(validFolder, validLoader, args.input_length, network, args.output_dim, args.prob_crps)\n",
    "        epoch_eval_wb_loss.append(loss_wb_eval.detach().cpu().numpy())\n",
    "        print('epoch eval loss:\\nmc loss: {:.5f}'.format(loss_mc_eval))\n",
    "        lr_scheduler.step(loss_mc_eval)\n",
    "        if loss_mc_eval >= best:\n",
    "            count += 1\n",
    "            print('eval loss is not improved for {} epoch'.format(count))\n",
    "        else:\n",
    "            count = 0\n",
    "            print('eval loss is improved from {:.5f} to {:.5f}, saving model'.format(best, loss_mc_eval))\n",
    "            save_model(save_dir + str(i) + \"_checkpoint.chk\")\n",
    "            best = loss_mc_eval\n",
    "\n",
    "        if count == args.patience:\n",
    "            print('early stopping reached, best loss is {:5f}'.format(best))\n",
    "            break\n",
    "    np.save(save_dir + \"eval_loss.npy\", np.array(epoch_eval_loss))\n",
    "    np.save(save_dir + \"eval_wb_loss.npy\", np.array(epoch_eval_wb_loss))\n",
    "\n",
    "def save_model(path):\n",
    "    torch.save({'net': network.state_dict(),\n",
    "                'optimizer': optimizer.state_dict()}, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fb3989",
   "metadata": {},
   "outputs": [],
   "source": [
    "transfer_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9ba742",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "args = parser.parse_args(args=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5564c2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(save_dir + 'args.txt', 'r') as f:\n",
    "    args.__dict__ = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619b8b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "del trainFolder\n",
    "del validFolder\n",
    "del trainLoader\n",
    "del validLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e48155c",
   "metadata": {},
   "outputs": [],
   "source": [
    "testFolder = wb_dataset(root=args.data, dataset_type=\"test\", frames_input=args.input_length,\n",
    "                              frames_output=args.output_length, prob = args.prob_crps)\n",
    "\n",
    "testLoader = torch.utils.data.DataLoader(testFolder,\n",
    "                                          batch_size=args.batch_size,\n",
    "                                          shuffle=False)\n",
    "\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04764814",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.convlstm and not args.prob_crps:\n",
    "    network = ConvLSTM(args.input_dim, args.hidden_dim, args.output_dim,\n",
    "                             args.kernel_size, device, dropout=args.dropout).to(device)\n",
    "elif args.convlstm and args.prob_crps:\n",
    "    network = ConvLSTM(2*args.input_dim, args.hidden_dim, 2*args.output_dim,\n",
    "                       args.kernel_size, device, dropout=args.dropout).to(device)\n",
    "elif args.saconvlstm and not args.prob_crps:   \n",
    "    network = SAConvLSTM(args.input_dim, args.hidden_dim, args.output_dim, args.attn_dim,\n",
    "                         args.kernel_size, device, dropout=args.dropout).to(device)\n",
    "else:\n",
    "    network = SAConvLSTM(2*args.input_dim, args.hidden_dim, 2*args.output_dim, args.attn_dim,\n",
    "                         args.kernel_size, device, dropout=args.dropout).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(network.parameters(), lr=args.learn_rate, weight_decay=args.weight_decay)    \n",
    "lr_scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.3, patience=0, verbose=True, min_lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fa261e",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_ep = 0\n",
    "for f in os.listdir(save_dir):\n",
    "    split = f.split(\"_\")\n",
    "    if len(split)==2 and split[1] == \"checkpoint.chk\":\n",
    "        if max_ep<int(split[0]): max_ep=int(split[0])\n",
    "chkpnt = str(max_ep) + \"_checkpoint.chk\"                                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359b5431",
   "metadata": {},
   "outputs": [],
   "source": [
    "chk = torch.load(save_dir + chkpnt)\n",
    "network.load_state_dict(chk['net'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed05047c",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_mc_test = infer(testLoader, args.input_length, network, args.output_dim, args.prob_crps)\n",
    "print(\"test rmse: \", loss_mc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853af754",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loss_WB_test = infer_WB(testFolder, testLoader, args.input_length, network, args.output_dim, args.prob_crps)\n",
    "print(\"test lat rmse: \")\n",
    "print(loss_WB_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3a9ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "item = testFolder.__getitem__(367)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab48cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = network(torch.from_numpy(item[None, :7, ...]).float().to(device), train=False).detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f97ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib.colors import Normalize\n",
    "from matplotlib import pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "from cartopy.util import add_cyclic_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771e915c",
   "metadata": {},
   "outputs": [],
   "source": [
    "longs = np.arange(0, 360, 5.625)\n",
    "lats = np.linspace(-90, 90, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84768a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "item = item*testFolder.long_std+testFolder.long_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3155643a",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = output[0]*testFolder.long_std+testFolder.long_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17d1e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "day_delta=0\n",
    "channel=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efeb5e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = item[7][channel]\n",
    "wrap_data, wrap_lon = add_cyclic_point(labels, coord=longs, axis=1)\n",
    "plt.figure(figsize=(20,9))\n",
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "ax.coastlines()\n",
    "ax.contourf(wrap_lon, lats, wrap_data, 100, transform=ccrs.PlateCarree(), norm = Normalize(vmin=240, vmax=305))\n",
    "ax.set_global()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5643975",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = item[11][channel]\n",
    "wrap_data, wrap_lon = add_cyclic_point(labels, coord=longs, axis=1)\n",
    "plt.figure(figsize=(20,9))\n",
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "ax.coastlines()\n",
    "ax.contourf(wrap_lon, lats, wrap_data, 100, transform=ccrs.PlateCarree(), norm = Normalize(vmin=240, vmax=305))\n",
    "ax.set_global()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9bf4db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0712e369",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = output[0][channel]\n",
    "wrap_data, wrap_lon = add_cyclic_point(labels, coord=longs, axis=1)\n",
    "plt.figure(figsize=(20,9))\n",
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "ax.coastlines()\n",
    "ax.contourf(wrap_lon, lats, wrap_data, 100, transform=ccrs.PlateCarree(), norm = Normalize(vmin=240, vmax=305))\n",
    "ax.set_global()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40e967b",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = output[4][channel]\n",
    "wrap_data, wrap_lon = add_cyclic_point(labels, coord=longs, axis=1)\n",
    "plt.figure(figsize=(20,9))\n",
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "ax.coastlines()\n",
    "ax.contourf(wrap_lon, lats, wrap_data, 100, transform=ccrs.PlateCarree(), norm = Normalize(vmin=240, vmax=305))\n",
    "ax.set_global()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
