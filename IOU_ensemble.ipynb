{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3324a5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from sa_convlstm import SAConvLSTM\n",
    "from convlstm import ConvLSTM\n",
    "from utils import *\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import sys\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import math\n",
    "import argparse\n",
    "import json\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c314b8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = './save_models/saclstm_dropout_0.2_epoch_8_pinchu_pandamonium_ensemble_1/'\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "args = parser.parse_args(args=\"\")\n",
    "with open(save_dir + 'args.txt', 'r') as f:\n",
    "    args.__dict__ = json.load(f)\n",
    "\n",
    "if args.convlstm and not args.prob_crps:\n",
    "    sam_network_1 = ConvLSTM(args.input_dim, args.hidden_dim, args.output_dim,\n",
    "                             args.kernel_size, device, dropout=args.dropout).to(device)\n",
    "elif args.convlstm and args.prob_crps:\n",
    "    sam_network_1 = ConvLSTM(2*args.input_dim, args.hidden_dim, 2*args.output_dim,\n",
    "                       args.kernel_size, device, dropout=args.dropout).to(device)\n",
    "elif args.saconvlstm and not args.prob_crps:   \n",
    "    sam_network_1 = SAConvLSTM(args.input_dim, args.hidden_dim, args.output_dim, args.attn_dim,\n",
    "                         args.kernel_size, device, dropout=args.dropout).to(device)\n",
    "else:\n",
    "    sam_network_1 = SAConvLSTM(2*args.input_dim, args.hidden_dim, 2*args.output_dim, args.attn_dim,\n",
    "                         args.kernel_size, device, dropout=args.dropout).to(device)\n",
    "\n",
    "max_ep = 0\n",
    "for f in os.listdir(save_dir):\n",
    "    split = f.split(\"_\")\n",
    "    if len(split)==2 and split[1] == \"checkpoint.chk\":\n",
    "        if max_ep<int(split[0]): max_ep=int(split[0])\n",
    "chkpnt = str(max_ep) + \"_checkpoint.chk\" \n",
    "chk = torch.load(save_dir + chkpnt)\n",
    "sam_network_1.load_state_dict(chk['net'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025a6306",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = './save_models/saclstm_dropout_0.2_epoch_8_pinchu_pandamonium_ensemble_2/'\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "args = parser.parse_args(args=\"\")\n",
    "with open(save_dir + 'args.txt', 'r') as f:\n",
    "    args.__dict__ = json.load(f)\n",
    "\n",
    "if args.convlstm and not args.prob_crps:\n",
    "    sam_network_2 = ConvLSTM(args.input_dim, args.hidden_dim, args.output_dim,\n",
    "                             args.kernel_size, device, dropout=args.dropout).to(device)\n",
    "elif args.convlstm and args.prob_crps:\n",
    "    sam_network_2 = ConvLSTM(2*args.input_dim, args.hidden_dim, 2*args.output_dim,\n",
    "                       args.kernel_size, device, dropout=args.dropout).to(device)\n",
    "elif args.saconvlstm and not args.prob_crps:   \n",
    "    sam_network_2 = SAConvLSTM(args.input_dim, args.hidden_dim, args.output_dim, args.attn_dim,\n",
    "                         args.kernel_size, device, dropout=args.dropout).to(device)\n",
    "else:\n",
    "    sam_network_2 = SAConvLSTM(2*args.input_dim, args.hidden_dim, 2*args.output_dim, args.attn_dim,\n",
    "                         args.kernel_size, device, dropout=args.dropout).to(device)\n",
    "\n",
    "max_ep = 0\n",
    "for f in os.listdir(save_dir):\n",
    "    split = f.split(\"_\")\n",
    "    if len(split)==2 and split[1] == \"checkpoint.chk\":\n",
    "        if max_ep<int(split[0]): max_ep=int(split[0])\n",
    "chkpnt = str(max_ep) + \"_checkpoint.chk\" \n",
    "chk = torch.load(save_dir + chkpnt)\n",
    "sam_network_2.load_state_dict(chk['net'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4574aa97",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = './save_models/saclstm_dropout_0.2_epoch_8_pinchu_pandamonium_ensemble_3/'\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "args = parser.parse_args(args=\"\")\n",
    "with open(save_dir + 'args.txt', 'r') as f:\n",
    "    args.__dict__ = json.load(f)\n",
    "\n",
    "if args.convlstm and not args.prob_crps:\n",
    "    sam_network_3 = ConvLSTM(args.input_dim, args.hidden_dim, args.output_dim,\n",
    "                             args.kernel_size, device, dropout=args.dropout).to(device)\n",
    "elif args.convlstm and args.prob_crps:\n",
    "    sam_network_3 = ConvLSTM(2*args.input_dim, args.hidden_dim, 2*args.output_dim,\n",
    "                       args.kernel_size, device, dropout=args.dropout).to(device)\n",
    "elif args.saconvlstm and not args.prob_crps:   \n",
    "    sam_network_3 = SAConvLSTM(args.input_dim, args.hidden_dim, args.output_dim, args.attn_dim,\n",
    "                         args.kernel_size, device, dropout=args.dropout).to(device)\n",
    "else:\n",
    "    sam_network_3 = SAConvLSTM(2*args.input_dim, args.hidden_dim, 2*args.output_dim, args.attn_dim,\n",
    "                         args.kernel_size, device, dropout=args.dropout).to(device)\n",
    "\n",
    "max_ep = 0\n",
    "for f in os.listdir(save_dir):\n",
    "    split = f.split(\"_\")\n",
    "    if len(split)==2 and split[1] == \"checkpoint.chk\":\n",
    "        if max_ep<int(split[0]): max_ep=int(split[0])\n",
    "chkpnt = str(max_ep) + \"_checkpoint.chk\" \n",
    "chk = torch.load(save_dir + chkpnt)\n",
    "sam_network_3.load_state_dict(chk['net'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c5e76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = './save_models/saclstm_dropout_0.2_epoch_8_pinchu_pandamonium_ensemble_4/'\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "args = parser.parse_args(args=\"\")\n",
    "with open(save_dir + 'args.txt', 'r') as f:\n",
    "    args.__dict__ = json.load(f)\n",
    "\n",
    "if args.convlstm and not args.prob_crps:\n",
    "    sam_network_4 = ConvLSTM(args.input_dim, args.hidden_dim, args.output_dim,\n",
    "                             args.kernel_size, device, dropout=args.dropout).to(device)\n",
    "elif args.convlstm and args.prob_crps:\n",
    "    sam_network_4 = ConvLSTM(2*args.input_dim, args.hidden_dim, 2*args.output_dim,\n",
    "                       args.kernel_size, device, dropout=args.dropout).to(device)\n",
    "elif args.saconvlstm and not args.prob_crps:   \n",
    "    sam_network_4 = SAConvLSTM(args.input_dim, args.hidden_dim, args.output_dim, args.attn_dim,\n",
    "                         args.kernel_size, device, dropout=args.dropout).to(device)\n",
    "else:\n",
    "    sam_network_4 = SAConvLSTM(2*args.input_dim, args.hidden_dim, 2*args.output_dim, args.attn_dim,\n",
    "                         args.kernel_size, device, dropout=args.dropout).to(device)\n",
    "\n",
    "max_ep = 0\n",
    "for f in os.listdir(save_dir):\n",
    "    split = f.split(\"_\")\n",
    "    if len(split)==2 and split[1] == \"checkpoint.chk\":\n",
    "        if max_ep<int(split[0]): max_ep=int(split[0])\n",
    "chkpnt = str(max_ep) + \"_checkpoint.chk\" \n",
    "chk = torch.load(save_dir + chkpnt)\n",
    "sam_network_4.load_state_dict(chk['net'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1c1fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = './save_models/saclstm_dropout_0.2_epoch_8_pinchu_pandamonium_ensemble_5/'\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "args = parser.parse_args(args=\"\")\n",
    "with open(save_dir + 'args.txt', 'r') as f:\n",
    "    args.__dict__ = json.load(f)\n",
    "\n",
    "if args.convlstm and not args.prob_crps:\n",
    "    sam_network_5 = ConvLSTM(args.input_dim, args.hidden_dim, args.output_dim,\n",
    "                             args.kernel_size, device, dropout=args.dropout).to(device)\n",
    "elif args.convlstm and args.prob_crps:\n",
    "    sam_network_5 = ConvLSTM(2*args.input_dim, args.hidden_dim, 2*args.output_dim,\n",
    "                       args.kernel_size, device, dropout=args.dropout).to(device)\n",
    "elif args.saconvlstm and not args.prob_crps:   \n",
    "    sam_network_5 = SAConvLSTM(args.input_dim, args.hidden_dim, args.output_dim, args.attn_dim,\n",
    "                         args.kernel_size, device, dropout=args.dropout).to(device)\n",
    "else:\n",
    "    sam_network_5 = SAConvLSTM(2*args.input_dim, args.hidden_dim, 2*args.output_dim, args.attn_dim,\n",
    "                         args.kernel_size, device, dropout=args.dropout).to(device)\n",
    "\n",
    "max_ep = 0\n",
    "for f in os.listdir(save_dir):\n",
    "    split = f.split(\"_\")\n",
    "    if len(split)==2 and split[1] == \"checkpoint.chk\":\n",
    "        if max_ep<int(split[0]): max_ep=int(split[0])\n",
    "chkpnt = str(max_ep) + \"_checkpoint.chk\" \n",
    "chk = torch.load(save_dir + chkpnt)\n",
    "sam_network_5.load_state_dict(chk['net'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b503e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "testFolder = wb_dataset(root=args.data, dataset_type=\"test\", frames_input=args.input_length,\n",
    "                              frames_output=args.output_length, prob = args.prob_crps)\n",
    "\n",
    "testLoader = torch.utils.data.DataLoader(testFolder,\n",
    "                                          batch_size=args.batch_size,\n",
    "                                          shuffle=False)\n",
    "\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc70afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "big_iou = []\n",
    "\n",
    "for i in range(len(testFolder)):\n",
    "    if i%50 == 0: print(i)\n",
    "    item = testFolder.__getitem__(i)    \n",
    "    item = item*testFolder.long_std+testFolder.long_mean\n",
    "    \n",
    "    output_1 = sam_network_1(torch.from_numpy(item[None, :7, ...]).float().to(device), train=False).detach().cpu().numpy()\n",
    "    output_1 = output_1[0]*testFolder.long_std+testFolder.long_mean\n",
    "    output_2 = sam_network_2(torch.from_numpy(item[None, :7, ...]).float().to(device), train=False).detach().cpu().numpy()\n",
    "    output_2 = output_2[0]*testFolder.long_std+testFolder.long_mean\n",
    "    output_3 = sam_network_3(torch.from_numpy(item[None, :7, ...]).float().to(device), train=False).detach().cpu().numpy()\n",
    "    output_3 = output_3[0]*testFolder.long_std+testFolder.long_mean\n",
    "    output_4 = sam_network_4(torch.from_numpy(item[None, :7, ...]).float().to(device), train=False).detach().cpu().numpy()\n",
    "    output_4 = output_4[0]*testFolder.long_std+testFolder.long_mean\n",
    "    output_5 = sam_network_5(torch.from_numpy(item[None, :7, ...]).float().to(device), train=False).detach().cpu().numpy()\n",
    "    output_5 = output_5[0]*testFolder.long_std+testFolder.long_mean\n",
    "    \n",
    "    output = (output_1 + output_2 + output_3 + output_4 + output_5)/5\n",
    "    var = ((output_1-output)**2 + (output_2-output)**2 + (output_3-output)**2 + (output_4-output)**2 + (output_5-output)**2)/5\n",
    "    iou_day= []\n",
    "    for d in range(5):\n",
    "        channel = 0\n",
    "        day = d\n",
    "        var_max_half_day = np.quantile(var[day, channel], 0.9)\n",
    "        var_set = var[day, channel]\n",
    "        var_set = var_set>var_max_half_day\n",
    "        del_day = np.abs(item[day+7][channel] - output[day+0][channel])\n",
    "        del_max_half_day = np.quantile(del_day, 0.9)\n",
    "        del_set = del_day > del_max_half_day\n",
    "        iou_day.append(np.sum(np.logical_and(var_set, del_set))/np.sum(np.logical_or(var_set, del_set)))\n",
    "    big_iou.append(iou_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f44a63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7481aa59",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "arr.mean(axis=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
